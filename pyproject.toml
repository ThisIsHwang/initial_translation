[build-system]
requires = ["hatchling>=1.25.0"]
build-backend = "hatchling.build"

[project]
name = "evalmt"
version = "0.1.0"
description = "vLLM-based MT generation + evaluation pipeline (WMT24++ + XCOMET/MetricX)."
readme = "README.md"
requires-python = ">=3.10"
license = { file = "LICENSE" }
authors = [{ name = "Your Team" }]

dependencies = [
  "pyyaml>=6.0.1",
  "tqdm>=4.66.0",
  "pandas>=2.1.0",
  "numpy>=1.26.0",
  "httpx>=0.27.0",
  "huggingface_hub>=0.24.0",

  # Metrics
  "unbabel-comet>=2.2.0",

  # Transformer stack (MetricX / general tokenization)
  "torch>=2.2.0",
  "transformers>=4.41.0",
  "sentencepiece>=0.2.0",
]

[project.optional-dependencies]
# vLLM is intentionally NOT pinned here because installation is environment-specific
# (CUDA/ROCm, and gpt-oss requires a special vLLM build). Install via scripts.
serve = [
  # "vllm"
]

dev = [
  "ruff>=0.5.0",
  "pytest>=8.0.0",
]

[project.scripts]
evalmt-prepare = "evalmt.cli.prepare_data:main"
evalmt-serve-vllm = "evalmt.cli.serve_vllm:main"
evalmt-wait-server = "evalmt.cli.wait_server:main"
evalmt-generate = "evalmt.cli.generate:main"
evalmt-score = "evalmt.cli.score:main"
evalmt-aggregate = "evalmt.cli.aggregate:main"

[tool.hatch.build.targets.wheel]
packages = ["evalmt"]
